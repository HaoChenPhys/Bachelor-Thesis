\chapter{Introduction}\label{chap:intro}

\section{Random spanning forests}
The random spanning forests is a particularly interesting model in statistical physics due to its special critical phenomena
and close connections to other statistical models. It decsribes the set of spanning forests $\scrF$, i.e., acyclic spanning subgraphs, of the underlying
lattice $G$ with each edge of the forest (referred to as occupied edge) weighted by $w$. The partition function of the model is written as
\begin{equation}\label{eq:SPF_partition}
	\scrZ_{\text{SF}} = \sum_{F \in \scrF} w^{|E_F|},
\end{equation}
where $|E_F|$ counts the number of edges in $F$. 

The model is reminiscent of the famous model of bond percolation, where each bond is occupied independently with probability $p$ and does not need to form a forest.
In percolation, it's well known that for dimension $d \geq 2$, there exists a critical point $0 < p_c < 1$ such that there is a unique giant cluster whose size is of the order of the system volume
at the supercritical phase $p > p_c$. On the other hand, Roland et al. \cite{Roland2021Percolation} have shown that the percolation of spanning forests happens only for $d \geq 3$ 
because of the geometrical constraint of the model. They also conjectured that the supercritical phase of the spanning-forest model is more interesting in terms of the scaling behaviors of non-giant clusters (trees). 
The random spanning forests can also be viewed as a special case of the $q$-state Potts model \cite{Potts1952, Wu1982}, another prototypical model in the study of phase transitions and critical phenomena.
At first, the $q$-state Potts model was proposed to describe ferromagnets on a crystalline lattice, and $q$ correspondingly takes integer values.
In 1972, a seminal work by Fortuin and Kasteleyn \cite{Fortuin1972} showed that the Potts model could be mapped to the random-cluster model, in which $q$ can be 
generalized to real numbers. In particular, as illustrated in Chap.~\ref{chap:SPF}, by taking the limit of $q\to 0$ appropriately,
the random-cluster model recovers to the spanning forests.

The theoretical studies of the spanning-forest model started with the paper by Caracciolo et al. \cite{Caracciolo2004}, in which they derived
an equivalent fermionic theory and showed that the theory could further be mapped onto a non-linear sigma model taking vales in the unit supersphere
$\mathbb{R}^{1|2}$ ($\text{OSp}(1|2)$-invariant sigma model) to all orders in perturbation theory. 
Later, Deng et al.\cite{Deng2007} presented Monte Carlo simulations of the model in spatial dimensions $d = 3, 4, 5$ and demonstrated that, for each case, there is a second-order phase transition at a finite weight
$w_c$. They further conjectured that the upper critical dimension is $d=6$. Recently, the authors in Ref.~\inlinecite{Roland2021Hyperbolic} extended the results
of Caracciolo et al. and reinterpreted the fermionic theory as a non-linear sigma model with hyperbolic target space $\mathbb{H}^{0|2}$, based on which
they proved that there is no phase transition in two dimensions using a Merminâ€“Wagner argument. With the formulation, they further
obtained \cite{Roland2021Percolation} that a percolation transition is present for $d \geq 3$, consistent with the previous numerics. Despite these developments, there remain several aspects of
the model worth exploring. In the thesis, we focus on the finite-size scaling behaviors of the non-giant clusters at the supercritical phase.
It has been proved that \cite{Luczak1992,Martin2018} when $G$ is a complete graph ($d=\infty$) and the system is at the supercritical phase, there are an unbounded number of clusters with sizes of the order of $|V|^{2/3}$ apart from the macroscopic component,
where $|V|$ is the system size. Remarkably, the scale of clusters at criticality, in this case, is also $|V|^{2/3}$. In other words, the supercritical
phase without the largest component looks like criticality. Our goal is to explore this phenomenon at finite dimensions, in particular $d=3$, using numerical methods.

\section{Monte Carlo methods}\label{sec:MC_intro}
We use Monte Carlo methods to study the spanning-forest model. This method plays a very important role in statistical physics by
providing a way to extract statistical properties from high-dimensional configuration space. To be more specific, in statistical
physics, we are usually interested in the ensemble average of various observables of the system of equilibrium, which is governed by a probability distribution $\pi$ over the configuration space $\scrS$ of the system. 
For observable $F(x)$ (as a function of state $x$), its ensemble average is defined as
\begin{equation}\label{eq:weighted_ave}
	\langle F \rangle = \sum_{\mu \in \scrS} F(\mu) \pi_\mu.
\end{equation}
Typically, the state space $\scrS$ is exponentially large, which makes the computation of Eq.~\eqref{eq:weighted_ave} by enumerating all possible states impractical.
Taking the Ising model as an example, for a system with a total of $N$ spins, the total number of spin configurations grows exponentially as $2^N$.
Unless there exists an analytic formula for $\langle F \rangle$, the computational resource required to compute $\langle F \rangle$ 
using Eq.~\eqref{eq:weighted_ave} grows exponentially with $N$.

The central idea of Monte Carlo simulations is to circumvent this difficulty by importance sampling, i.e., directly sampling states from the distribution
$\pi$, and then compute the unweighted average as the estimated value of the ensemble average, i.e.,
\begin{equation}
	\bar{F} = \frac{1}{n}\sum_{i=1}^n F(X_i) \approx \langle F \rangle,
\end{equation}
where $X_i$ is the configuration at sampling step $i$, and $n$ is the number of sampling steps. In practice, one can get a decent estimate of $\langle F \rangle $ with $n$ much smaller
than the dimension of the state space $\scrS$. The reason is that this procedure takes account of those most `important' configurations,
i.e., configurations with large statistical weights, and ignores those that have negligible contributions on $\langle F \rangle$.

In order to simulate the distribution $\pi$, Monte Carlo methods construct a Markov chain $\scrM$ with transition probability matrix 
$P = \{p_{\mu\nu}\}_{\mu, \nu \in \scrS} = \{\mathbb{P}(X_{t+1} = \nu|X_{t} = \mu)\}_{\mu, \nu\in \scrS}$ satisfying the following conditions:
\begin{enumerate}[label=(\alph*)]
	\item The distribution $\pi$ is the stationary distribution of $\scrM$, i.e.,  $\sum_\mu \pi_{\mu} p_{\mu\nu} = \pi_\nu$ for all $\nu\in \scrS$.
	\item The Markov chain $\scrM$ is ergodic, i.e., there exists a positive integer $t_0$, such that for all paris $\mu, \nu\in \scrS$, 
	$\mathbb{P}(X_t = \nu|X_0 = \mu) > 0$ for $t > t_0$.
\end{enumerate}
Condition (b) ensures that it's possible to sample any state in $\scrS$ in a Markov chain starting from an arbitrary state.
One common way to obtain a transition probability $p_{\mu\nu}$ satisfying condition (a) is by further imposing the detailed balance condition
\begin{equation}
	\pi_{\mu} p_{\mu\nu} = \pi_{\nu} p_{\nu \mu}, \quad \forall \mu, \nu \in S, \mu \neq \nu.
\end{equation}

The content we present above only gives a rough idea of the Monte Carlo methods. For a more detailed description, please see, e.g., Ref.~\inlinecite{Sokal1997, Landau2014, Binder2010} and references therein.
In Chap.~\ref{chap:Algo}, we will elaborate on a specific Monte Carlo algorithm for simulating the spanning forests.

\section{Plan of the thesis}
The thesis is organized as follows. In Chap.~\ref{chap:SPF}, we elucidate the relation between the random spanning forests and
the Potts model and derive the corresponding fermionic representation. Then we summarize the analytical results from Ref.~\inlinecite{Roland2021Hyperbolic,Roland2021Percolation}.
The Monte Carlo algorithm and data structure implemented in this work is covered in Chap.~\ref{chap:Algo}. In Chap.~\ref{chap:results}, we analyze the simulation results, and a conclusion is given in Chap.~\ref{chap:conclusion}.


